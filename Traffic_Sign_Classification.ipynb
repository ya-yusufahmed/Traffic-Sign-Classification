{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r2iWMvSm9Ruh"
      },
      "source": [
        "In this project, using Convolutional Neural Network to build train and test a traffic sign classification model. The model will be built using tensorflow and keras. It is a multiclass classification problem. This model can be used to make smarter cars."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "wf7-EsX99P7J",
        "outputId": "ee36b7a7-925b-4ab1-cd21-42ada3028a1f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-26cce6ac-5fb1-4e26-96ef-0f339bcd6716\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-26cce6ac-5fb1-4e26-96ef-0f339bcd6716\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "ename": "TypeError",
          "evalue": "'NoneType' object is not subscriptable",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-e79310375397>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Run this cell and select the kaggle.json file downloaded from the Kaggle account settings page.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mupload\u001b[0;34m()\u001b[0m\n\u001b[1;32m     67\u001b[0m   \"\"\"\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m   \u001b[0muploaded_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_upload_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmultiple\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m   \u001b[0;31m# Mapping from original filename to filename as saved locally.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m   \u001b[0mlocal_filenames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36m_upload_files\u001b[0;34m(multiple)\u001b[0m\n\u001b[1;32m    161\u001b[0m   \u001b[0mfiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_collections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m   \u001b[0;32mwhile\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'action'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'complete'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m     result = _output.eval_js(\n\u001b[1;32m    165\u001b[0m         'google.colab._files._uploadFilesContinue(\"{output_id}\")'.format(\n",
            "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
          ]
        }
      ],
      "source": [
        "# Run this cell and select the kaggle.json file downloaded from the Kaggle account settings page.\n",
        "from google.colab import files\n",
        "files.upload()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q93aviRocggV"
      },
      "source": [
        "starting by connecting to Kaggle using Kaggle API which can be downloaded from your Kaggle account's settings and uploading it here(upload box)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "K6t6UlzY9ZPH"
      },
      "outputs": [],
      "source": [
        "# Next, install the Kaggle API client.\n",
        "!pip install -q kaggle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rgZNe-6idYTM"
      },
      "source": [
        "Installing kaggle api using pip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "hdN3ZFKS9bzc"
      },
      "outputs": [],
      "source": [
        "# The Kaggle API client expects this file to be in ~/.kaggle, so move it there.\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "\n",
        "# This permissions change avoids a warning on Kaggle tool startup.\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mlTVvA3gck_p"
      },
      "source": [
        "Setting up Kaggle using Kaggle API."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "oEWoKy939e0S"
      },
      "outputs": [],
      "source": [
        "# Creating directory and changing the current working directory\n",
        "!mkdir traffic_sign_dataset\n",
        "%cd traffic_sign_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SJKt8mPDcpV-"
      },
      "source": [
        "To store the data we will create a new directory and make it as current working directory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "qzGxQr3T9e_q"
      },
      "outputs": [],
      "source": [
        "# Searching for dataset\n",
        "!kaggle datasets list -s gtsrb-german-traffic-sign"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PKrC4jXFcuBi"
      },
      "source": [
        "Searching Kaggle for the required dataset using search option(-s) with title 'dogbreedidfromcomp'. We can also use different search options like searching competitions, notebooks, kernels, datasets, etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "YJdl3GIP9fCs"
      },
      "outputs": [],
      "source": [
        "# Downloading dataset and coming out of directory\n",
        "!kaggle datasets download meowmeowmeowmeowmeow/gtsrb-german-traffic-sign\n",
        "%cd .."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Jrsy575cx7e"
      },
      "source": [
        "After searching the data next step would be downloading the data into collab notebook using references found in search option."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "iOHRCQHJ9zu0"
      },
      "outputs": [],
      "source": [
        "# Unzipping downloaded file and removing unusable file\n",
        "!unzip traffic_sign_dataset/gtsrb-german-traffic-sign.zip -d traffic_sign_dataset\n",
        "!rm traffic_sign_dataset/gtsrb-german-traffic-sign.zip\n",
        "!rm -rf traffic_sign_dataset/Meta\n",
        "!rm -rf traffic_sign_dataset/meta\n",
        "!rm -rf traffic_sign_dataset/test\n",
        "!rm -rf traffic_sign_dataset/train\n",
        "!rm traffic_sign_dataset/Meta.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V5oG3Q8Ac9lA"
      },
      "source": [
        "In this section unzipping the data which is downloaded and removing the irrelevant files."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "YnDWKmh39zx4"
      },
      "outputs": [],
      "source": [
        "# Importing libraries\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.image import imread\n",
        "import seaborn as sns\n",
        "import random\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import  train_test_split\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, Dropout, Conv2D, MaxPool2D"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RP-tswFNdrjj"
      },
      "source": [
        "Importing required libraries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "3_ERdvte_YIw"
      },
      "outputs": [],
      "source": [
        "# Plotting 12 images to check dataset\n",
        "plt.figure(figsize=(12,12))\n",
        "path = \"traffic_sign_dataset/Test\"\n",
        "for i in range(1,17):\n",
        "    plt.subplot(4,4,i)\n",
        "    plt.tight_layout()\n",
        "    rand_img = imread(path +'/'+ random.choice(sorted(os.listdir(path))))\n",
        "    plt.imshow(rand_img)\n",
        "    plt.xlabel(rand_img.shape[1], fontsize = 10)#width of image\n",
        "    plt.ylabel(rand_img.shape[0], fontsize = 10)#height of image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NDzMeI-9d5Db"
      },
      "source": [
        "Visualizing some images of traffic sign from the test dataset. It is seen that here the dimension of images are uneven."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "xaihvai8BTxH"
      },
      "outputs": [],
      "source": [
        "# As size of images are different we have to make them equal so we will take mean of dimanesions\n",
        "dim1 = []\n",
        "dim2 = []\n",
        "\n",
        "for i in range(0,43):\n",
        "    labels = 'traffic_sign_dataset/Train' + '/{0}'.format(i)\n",
        "    image_path = os.listdir(labels)\n",
        "    for x in image_path:\n",
        "        img = imread(labels + '/' + x)\n",
        "        dim1.append(img.shape[0])\n",
        "        dim2.append(img.shape[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b6-4uIV2edAf"
      },
      "source": [
        "For further processing the images of same dimension will be required will start storing the dimension of all the images from training dataset from all 43 classes.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "1k0kjKHqDYvZ"
      },
      "outputs": [],
      "source": [
        "#Printing mean dimension of images\n",
        "print(\"Dimension 1 Mean : \",np.mean(dim1), \" Dimension 2 Mean : \",np.mean(dim2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9xm6X4AIfIdG"
      },
      "source": [
        "Now finding out the mean value of both the dimensions and analyse them. Here, it is seen that (50,50) is the average shape for all the images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "FYlG6oahDsgn"
      },
      "outputs": [],
      "source": [
        "# Now we will reshape the images to (50,50)\n",
        "images = []\n",
        "label_id = []\n",
        "\n",
        "for i in range(43):\n",
        "    labels = 'traffic_sign_dataset/Train' + '/{0}'.format(i)\n",
        "    image_path = os.listdir(labels)\n",
        "    for x in image_path:\n",
        "        img = Image.open(labels + '/' + x)\n",
        "        img = img.resize((50,50))\n",
        "        img = np.array(img)\n",
        "        images.append(img)\n",
        "        label_id.append(i)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3zr8Ip_8giBv"
      },
      "source": [
        "Now reshaping the images into (50,50) and also store their label ids."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "QbY9MSaaEFeq"
      },
      "outputs": [],
      "source": [
        "#Converting images into numpy array\n",
        "images = np.array(images)\n",
        "#The pixel value of each image ranges between 0 and 255\n",
        "#Dividing each image by 255 will scale the values between 0 and 1. This is also known as normalization.\n",
        "images = images/255"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p04xcb7cg01H"
      },
      "source": [
        "Now converting all the images into numpy array and normalize them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "spCgQYCMESBQ"
      },
      "outputs": [],
      "source": [
        "label_id = np.array(label_id)\n",
        "label_id.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FKQomtbYg-_0"
      },
      "source": [
        "Storing the label ids into numpy array and printing the shape. Here label id is observed that there are 39209 label ids."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "cQZXYvNzEVkw"
      },
      "outputs": [],
      "source": [
        "images.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1WDpgwyMhNpV"
      },
      "source": [
        "Checking the shape of the images. There are 39209 images with a shape of (50,50,3.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "6WC2sIMmEWYU"
      },
      "outputs": [],
      "source": [
        "# Visualize the number of classes count\n",
        "label_counts = pd.DataFrame(label_id).value_counts()\n",
        "label_counts.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u7k6aiXfhrjs"
      },
      "source": [
        "will observe images per class for checking whether the data is balanced or not. From the result it can be said that data is balanced."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "m2hWQ3YIEc-o"
      },
      "outputs": [],
      "source": [
        "#Splitting the data\n",
        "x_train, x_val, y_train, y_val = train_test_split(images, label_id , test_size = 0.2, random_state = 42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aAoDpM03iqqI"
      },
      "source": [
        "The next step would be to split the data into training and validation with 80% of training data and 20% of validation data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "gdnFqZybEupr"
      },
      "outputs": [],
      "source": [
        "#keras has a built-in function for one-hot encoding.\n",
        "y_train_cat = to_categorical(y_train)\n",
        "y_val_cat = to_categorical(y_val)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hfn9rGf1kGPv"
      },
      "source": [
        "Converting the classes column into categorical using to_categorical() function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Y_d1-ckeE2aw"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(filters = 64, kernel_size = (3,3), input_shape = x_train.shape[1:], activation = 'relu', padding = 'same'))\n",
        "model.add(MaxPool2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Conv2D(filters = 64, kernel_size = (3,3), activation = 'relu'))\n",
        "model.add(MaxPool2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation = 'relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(43, activation = 'softmax'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6UdL6JTvkW8E"
      },
      "source": [
        "Defining the model architecture. In this all the layers will be defined with their input shape kernel size, activation, etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "j0EWaNciJry-"
      },
      "outputs": [],
      "source": [
        "model.compile(loss = 'sparse_categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yl_aHjtOk9tw"
      },
      "source": [
        "Compiling the model using metrics, optimizer and loss as required and printing out the summary of the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ocYgOv-0JsfT"
      },
      "outputs": [],
      "source": [
        "model.fit(x_train, y_train, epochs = 10, batch_size = 128, validation_data = (x_val, y_val), verbose = 2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GoG9cFlhlMOC"
      },
      "source": [
        "Now fitting the model and will observe how our is getting trained on each epoch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "doO1VovGJ5i0"
      },
      "outputs": [],
      "source": [
        "evaluation = pd.DataFrame(model.history.history)\n",
        "evaluation[['accuracy', 'val_accuracy']].plot()\n",
        "evaluation[['loss', 'val_loss']].plot()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6LKSAcQGl_mJ"
      },
      "source": [
        "Visualizing the accuracy and loss per epoch. For this will store the model history in the pandas dataframe and plot them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Ixsgr0jlQTFP"
      },
      "outputs": [],
      "source": [
        "test_path = 'traffic_sign_dataset/Test'\n",
        "!rm traffic_sign_dataset/Test/GT-final_test.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kokV342Nmlkk"
      },
      "source": [
        "Creating the variable which has path of test dataset. As the dataset was downloded, I found out that their is a GT-final_test.csv file in the test images folder which cannot be processed. So, we will remove that file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "3TXtpJbTQXFU"
      },
      "outputs": [],
      "source": [
        "#defining a function that will scale images\n",
        "from PIL import Image\n",
        "\n",
        "def scaling(test_images, test_path):\n",
        "    images = []\n",
        "\n",
        "    image_path = test_images\n",
        "\n",
        "    for x in image_path:\n",
        "        img = Image.open(test_path + '/' + x)\n",
        "        img = img.resize((50,50))\n",
        "        img = np.array(img)\n",
        "        images.append(img)\n",
        "\n",
        "    #Converting images into numpy array\n",
        "    images = np.array(images)\n",
        "    #The pixel value of each image ranges between 0 and 255\n",
        "    #Dividing each image by 255 will scale the values between 0 and 1. This is also known as normalization.\n",
        "    images = images/255\n",
        "\n",
        "    return images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gfonPVJznMRB"
      },
      "source": [
        "Next step, creating a function to resize the test images converting them into a numpy array and normalize them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "0drYIKsmQcga"
      },
      "outputs": [],
      "source": [
        "test_images = scaling(sorted(os.listdir(test_path)),test_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pdn-LHM2nfx-"
      },
      "source": [
        "Calling the above created function on test images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "AB0nhfiDQc6C"
      },
      "outputs": [],
      "source": [
        "test = pd.read_csv('traffic_sign_dataset/Test.csv')\n",
        "y_test = test['ClassId'].values\n",
        "y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "mU_PPywvF20M"
      },
      "outputs": [],
      "source": [
        "test.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hSLIQkB5no2Q"
      },
      "source": [
        "Next I will read label ids from Test.csv and store the values of the class id in y_test variable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "g4OjbwyGQjcw"
      },
      "outputs": [],
      "source": [
        "y_pred = model.predict(test_images)\n",
        "y_pred = np.argmax(y_pred, axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zu23-QJzoOFL"
      },
      "source": [
        "Now using the model to make predictions on our test images and save them in y_pred."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "diVVLWzvEGNu"
      },
      "outputs": [],
      "source": [
        "# Storing all lables\n",
        "all_lables = ['Speed limit (20km/h)','Speed limit (30km/h)','Speed limit (50km/h)','Speed limit (60km/h)',\n",
        "              'Speed limit (70km/h)','Speed limit (80km/h)','End of speed limit (80km/h)','Speed limit (100km/h)',\n",
        "              'Speed limit (120km/h)','No passing','No passing for vechiles over 3.5 metric tons',\n",
        "              'Right-of-way at the next intersection','Priority road','Yield','Stop','No vechiles',\n",
        "              'Vechiles over 3.5 metric tons prohibited','No entry','General caution','Dangerous curve to the left',\n",
        "              'Dangerous curve to the right','Double curve','Bumpy road','Slippery road','Road narrows on the right',\n",
        "              'Road work','Traffic signals','Pedestrians','Children crossing','Bicycles crossing','Beware of ice/snow',\n",
        "              'Wild animals crossing','End of all speed and passing limits','Turn right ahead','Turn left ahead',\n",
        "              'Ahead only','Go straight or right','Go straight or left','Keep right','Keep left','Roundabout mandatory',\n",
        "              'End of no passing','End of no passing by vechiles over 3.5 metric']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WoULg2ysot7D"
      },
      "source": [
        "Storing the labels according to the image classes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "aKCGS13aQp-P"
      },
      "outputs": [],
      "source": [
        "# Visualize test image\n",
        "img = Image.open(test_path + '/00004.png')\n",
        "img"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7JqaYFECo373"
      },
      "source": [
        "Let's visualize test image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "agT8igHnHNDj"
      },
      "outputs": [],
      "source": [
        "# Original label\n",
        "print(\"Original label : \",all_lables[y_test[1]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sIyb3C-XpEGZ"
      },
      "source": [
        "Finding out original label for the image above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "i9YQO0jqIj8j"
      },
      "outputs": [],
      "source": [
        "# Predicted label\n",
        "print(\"Predicted label : \",all_lables[y_pred[1]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pBItNkDZpMK0"
      },
      "source": [
        "Finding out the predicted label for the image above."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YwHeXF2OpWXi"
      },
      "source": [
        "## Conclusion:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WcTEz8_dpWaw"
      },
      "source": [
        "I started with downloading the dataset, preprocessing it, created the model and found out the predictions using the model. During preprocessing I found that this dataset has 43 classes. Model reached an accuracy of 95%+ in just 50 epochs, I can further optimize the model using hyper parameter tuning and reach a higher accuracy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xxAFt2A1qKWM"
      },
      "source": [
        "# Scope:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M__KNJw4qMKT"
      },
      "source": [
        "\n",
        "\n",
        "```\n",
        "# This is formatted as code\n",
        "```\n",
        "\n",
        "This model can be used in self driving cars which will enable them to automatically recognize traffic signs similarly the driver alert system inside cars will help and protect drivers by understanding the traffic signs around them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "INSToaqiIyJv"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}